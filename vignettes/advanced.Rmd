---
title: "rbmi Advanced Functionality"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{advanced}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
)
```


## Introduction

The purpose of this vignette is to provide an overview of some of the more advanced
features that the package offers. Please note that this vignette
will not cover any of the underlying statistical theory. 


In order to demonstrate these advanced functions we will first create a simulated dataset
and perform a mock analysis so that we have all the require objects available to us.

```{r}
library(rbmi)
library(dplyr)
set.seed(169)
dat_full <- simulate_data(n = 120) %>% as_tibble()

## Introduce missingness
dat <- dat_full
missing_index_vis2 <- rbinom(nrow(dat), 1, 0.3) == 1 & dat$visit == "visit_2"
missing_index_vis3 <- rbinom(nrow(dat), 1, 0.4) == 1 & dat$visit == "visit_3"
dat[missing_index_vis2, "outcome"] <- NA_real_
dat[missing_index_vis3, "outcome"] <- NA_real_

# create data_ice setting the imputation method to MAR for
# each patient with at least one missing value
dat_ice <- dat %>% 
    arrange(id, visit) %>% 
    filter(is.na(outcome)) %>% 
    group_by(id) %>% 
    slice(1) %>%
    ungroup() %>% 
    select(id, visit) %>% 
    mutate(strategy = "MAR")


# Define the names of key variables in our dataset using `set_vars()`
# Note that covariates argument can contain interactions
vars <- set_vars(
    outcome = "outcome",
    visit = "visit",
    subjid = "id",
    group = "group",
    covariates = c("age", "sex", "group*visit")
)


```


## Efficiently Changing Imputation Strategies

The `draws()` function is by far the most computationally intensive function in
rbmi. It is recognised that this can pose an issue for doing repeated analyses
using different imputation strategies. To try and address this issue `impute()`
has an additional argument `update_strategies` which allows the user to 
change each subjects imputation strategy without having to re-run the `draws()`
function.

Please note though that this functionality comes with a few key limitations:
- The visit on which the ICE occured can not be updated.
- The imputation strategy cannot be changed from MAR to a non-MAR strategy if .
there is any observed data after the ICE visit

Both of these restrictions exist to protect the validity of the imputation model.
It is worth noting that whilst a strategy of MAR cannot be changed to non-MAR, a
non-MAR strategy can be changed to MAR. The only potential issue with such a change
is that this means that the imputation model hasn't used all of the available data
and as such a warning is issued to the user to inform them of this. 

As an example, lets say in our first analysis we want to use the jump
to reference imputation strategy but then as a sensitivity we wanted to use
the copy increments from reference strategy, this could be done as follows:

```{r}

# create data_ice setting the imputation method to MAR for
# each patient with at least one missing value
dat_ice$strategy <- "JR"
dat_ice

drawObj <- draws(
    data = dat, 
    data_ice = dat_ice, 
    vars = vars, 
    method = method_condmean(n_samples = 15)
)

imputeObj_JR <- impute(
    drawObj,
    references = c("A" = "B", "B" = "B")
)
anaObj_JR <- analyse(
    imputeObj_JR, 
    vars = set_vars()
)
pool(anaObj_JR)


dat_ice_CIR <- dat_ice
dat_ice_CIR$strategy <- "CIR"

imputeObj_JR <- impute(
    drawObj, 
    references = c("A" = "B", "B" = "B"), 
    update_strategy = dat_ice_CIR
)
anaObj_JR <- analyse(
    imputeObj_JR, 
    vars = set_vars()
)
pool(anaObj_JR)
```


## Custom Strategy Functions

Out of the box rbmi has support for the following imputation strategies:

- Missing at Random (MAR)
- Jump to Reference (JR)
- Copy Reference (CR)
- Copy Increments from Reference (CIR)
- Last Mean Carried Forward (LMCF)

However, rbmi also supports the ability for users to define their own imputation 
strategies. To do this their are 3 things the user needs to do:

1. Define their own imputation strategy function.
2. Specify patients use this strategy in the `data_ice` dataset provided to `draws()`.
3. Provide the imputation strategy function to `impute()`.

This is perhaps better demonstrated by an example. For this example we will implement a strategy
in which all post-ice missing values are be imputed by the average outcome between 
the subject's group and reference group.

To do this we first need to define our imputation function. This function must take
3 arguments: `pars_group`, `pars_ref` and `index_mar`.  Both `pars_group` and `pars_ref`
will be a list with elements `mu` (a numeric vector) and `sigma` (a covariance matrix)
which represent the distributions that patients conditional distribution assuming they 
below to their group and reference group respectively.  The `index_mar` argument
is then a logical vector indicating which visits for the subject meet the MAR assumption . 
I.e. this cam be used to identify the observations that occur after a non-MAR 
intercurrent event (ICE).

As such out example imputation function could be coded as:


```{r}
strategy_AVG <- function(pars_group, pars_ref, index_mar) {
    mean_xy <- function(x,y) mean(c(x,y))
    mu_mean <- mapply(
        mean_xy,
        pars_group$mu,
        pars_ref$mu,
        SIMPLIFY = T
    )
    x <- pars_group
    x$mu[!index_mar] <- mu_mean[!index_mar]
    return(x)
}
```

And an example showing its use:
```{r}
pars_group <- list(
    mu = c(1,2,3),
    sigma = as_vcov(c(1,3,2) , c(0.4, 0.5, 0.45))
)

pars_ref <- list(
    mu = c(5,6,7),
    sigma = as_vcov(c(2,1,1) , c(0.7, 0.8, 0.5))
)

index_mar <- c(TRUE, TRUE, FALSE)

strategy_AVG(pars_group, pars_ref, index_mar)
```

To incorporate this into rbmi, `data_ice` needs to be updated such that subjects are 
specified as using this `AVG` imputation strategy. Additionally the function then needs
to be provided to `impute()` via the `getStrategies()` function as shown below:

```{r}
dat_ice$strategy <- "AVG"
dat_ice

drawObj <- draws(
    data = dat, 
    data_ice = dat_ice, 
    vars = vars, 
    method = method_condmean(n_samples = 10)
)

imputeObj <- impute(
    drawObj, 
    references = c("A" = "B", "B" = "B"), 
    strategies = getStrategies(AVG = strategy_AVG)
)
```



## Custom Analysis Functions

By default rbmi will analyses the data by performing an ancova at each visit independently,
returning the "treatment effect" estimate as well as the corresponding least square means
for each group. If the user wants to perform a different analysis, or return different
statistics from the analysis, then this can be done by using a custom analysis function.

The rules for this custom analysis function are that it must take a `data.frame` as its 
first argument and must return a named `list` with each element itself being a `list` containing 
a single numeric element called `est` (or additionally `se` and `df` if you had originally specified
`method_bayes()` or `method_approxbayes()`).  As an example lets say that for your analysis
you are also interested in calculating the overall mean at each visit (i.e. not the treatment
effect), this could then be done as follows:

```{r}
mean_fun <- function(dat, ...) {

    mod <- dat %>% 
        group_by(visit) %>% 
        summarise(
            m = mean(outcome),
            se = sqrt(var(outcome) / n()),
            df = n() - 1
        )
    
    results <- mapply(
        function(x, y, z) list(est = x, se = y, df = z),
        mod$m,
        mod$se,
        mod$df,
        SIMPLIFY = FALSE
    )
    
    names(results) <- paste0("mean_", mod$visit)
    return(results)
}
```

This analysis function can then be used in combination with `analyse()` as follows:

```{r}
anlObj <- analyse(
    imputations = imputeObj,
    fun = mean_fun
)

pool(anlObj)
```



## Delta Adjustment

The `delta` argument of `analyse()` allows users to modify the outcome variable
which can be utalised as part of a tipping point or sensitivity analysis. To do 
this the user needs to provide a `data.frame` containing a column for the subject
and visit which identifies the observation to be adjusted, and then a 3rd column
called `delta` which specifies how much to offset the outcome by.

The `delta_template()` function creates a skeleton `data.frame` containing
1 row per subject per visit with the value of delta set to 0 for all observations.
The `delta_template()` function though also has two additional arguments `delta`
and `dlag` which allows the user to specify initial accumulative delta values based upon a
default value and a scaling coefficient based upon how far away the visit
in question is from the ICE visit. 

More specifically; the `delta` argument specifies the default amount of delta
that should be applied to each visit (if it was both post-ICE & unobserved), whilst
`dlag` specifies the scaling coefficient to be applied based upon the visits proximity
to the ICE visit. This is perhaps best illustrated with an example:

Let `delta = c(5,6,7,8)` and `dlag=c(1,2,3,4)` (i.e. assuming there are 4 visits) and lets 
say that the subject had an ICE on visit 2. The calculation would then be as follows:

```
v1  v2  v3  v4
--------------
 5   6   7   8  # delta assigned to each visit
 0   1   2   3  # scaling starting from the first visit after the subjects ICE
--------------
 0   6  14  24  # delta * scaling
--------------
 0   6  20  44  # accumulative sum / delta to be applied to each visit
```

That is to say the subject would have a delta offset of 0 applied for visit-1, 6 for 
visit-2, 20 for visit-3 and 44 for visit-4. As a comparison, lets say that the subject 
instead had their ICE on visit 3, the calculation would then be as follows:

```
v1  v2  v3  v4
--------------
 5   6   7   8  # delta assigned to each visit
 0   0   1   2  # scaling starting from the first visit after the subjects ICE
--------------
 0   0   7  16  # delta * scaling
--------------
 0   0   7  23  # accumulative sum / delta to be applied to each visit
 ```
 
In terms of practical usage, lets say that you wanted a delta of 5 to be used for all
post ICE visits regardless of their proximity to the ICE visit. This can be achieved
by setting `delta = c(5,5,5,5)` and `dlag = c(1,0,0,0)`. For example lets say a subject
had their ICE on visit-1, then the calculation would be as follows:

```
v1  v2  v3  v4
--------------
 5   5   5   5  # delta assigned to each visit
 1   0   0   0  # scaling starting from the first visit after the subjects ICE
--------------
 5   0   0  0  # delta * scaling
--------------
 5   5   5  5  # accumulative sum / delta to be applied to each visit
 ```
 
Another way of using these arguments is to set delta to be the difference in time 
between visits and dlag to be the amount of delta per unit of time. For example 
lets say that we have a visit on weeks 1, 5, 6 & 9 and that we want a delta of 3
to be applied for each week after an ICE. This can be achieved by setting 
`delta = c(0,4,1,3)` (the difference in weeks between each visit) and `dlag = c(3, 3, 3, 3)`. 
For example lets say we have a subject who had their ICE on week-5 (i.e. visit-2) then 
the calculation would be:

```
v1  v2  v3  v4
--------------
 0   4   1   3  # delta assigned to each visit
 0   0   3   3  # scaling starting from the first visit after the subjects ICE
--------------
 0   0   3   9  # delta * scaling
--------------
 0   0   3  12  # accumulative sum / delta to be applied to each visit
```

i.e. on week-6 (1 week after the ICE) they have a delta of 3 and on week-9 (4 weeks
after the ICE) they have a delta of 12




