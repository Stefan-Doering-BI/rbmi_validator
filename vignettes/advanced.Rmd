---
title: "rbmi Advanced Functionality"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{advanced}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
)
```


## Introduction

The purpose of this vignette is to provide an overview of some of the more advanced
features of the `rbmi` package. 


In order to demonstrate these advanced functions we will first create a simulated dataset
and perform a mock analysis so that all the require objects are available.

```{r}
library(rbmi)
library(dplyr)
set.seed(169)
dat_full <- simulate_data(n = 120) %>% as_tibble()

## Introduce missingness
dat <- dat_full
missing_index_vis2 <- rbinom(nrow(dat), 1, 0.3) == 1 & dat$visit == "visit_2"
missing_index_vis3 <- rbinom(nrow(dat), 1, 0.4) == 1 & dat$visit == "visit_3"
dat[missing_index_vis2, "outcome"] <- NA_real_
dat[missing_index_vis3, "outcome"] <- NA_real_

# create data_ice setting the imputation method to MAR for
# each patient with at least one missing value
dat_ice <- dat %>%
    arrange(id, visit) %>%
    filter(is.na(outcome)) %>%
    group_by(id) %>%
    slice(1) %>%
    ungroup() %>%
    select(id, visit) %>%
    mutate(strategy = "MAR")


# Define the names of key variables in our dataset using `set_vars()`
# Note that covariates argument can contain interactions
vars <- set_vars(
    outcome = "outcome",
    visit = "visit",
    subjid = "id",
    group = "group",
    covariates = c("age", "sex", "group*visit")
)
```


## Efficiently Changing Imputation Strategies

The `draws()` function is by far the most computationally intensive function in `rbmi`. 
In some settings, it may be important to explore the impact of a different 
reference-based imputation strategy than the one chosen for the main analysis. 
This change in the imputation strategy does not affect the imputation model but it does 
affect the subsequent imputation step. 
In order to allow changes in the imputation strategy without having to re-run the 
`draws()` function, the function `impute()` has an additional argument `update_strategies`.  

Please note though that this functionality comes with a some key limitations:
From a theoretical point of view, such updates are only sensible if the base imputation model and the data to which it is fitted is also applicable to the revised imputation strategy. For example, as described in the help to the `draws()` function, observed post-ICE data are included in the imputation model for the MAR strategy but excluded for non-MAR strategies. For this reason, the imputation strategy cannot be changed from MAR to a non-MAR strategy via argument `update_strategies` in case there are any observed data after the ICE. A change from a non-MAR to MAR triggers a warning because in this case the imputation model was not fitted to all relevant data and may be inefficient. Similarly, it is not possible to change the first visit which is affected by an ICE via argument `update_strategies`. 

As an example, let's assume we want to use the copy  increments from reference strategy for the main analysis and explore the jump to reference imputation strategy as a sensitivity analysis. If we use approximate Bayesian multiple imputation with 10 random imputation, this could be implemented as follows:

```{r}
dat_ice_CIR <- dat_ice
dat_ice_CIR$strategy <- "CIR"
dat_ice_CIR

draw_obj <- draws(
    data = dat,
    data_ice = dat_ice_CIR,
    vars = vars,
    method =  method_approxbayes(n_sample=10)
)

impute_obj_CIR <- impute(
    draw_obj,
    references = c("A" = "B", "B" = "B")
)

ana_obj_CIR <- analyse(
    impute_obj_CIR,
    vars = set_vars()
)

pool(ana_obj_CIR, type = "percentile")

## Now we re-use our draws samples but using the Jump to Reference 
## Imputation strategy

dat_ice_JR <- dat_ice
dat_ice_JR$strategy <- "JR"
dat_ice_JR

impute_obj_JR <- impute(
    draw_obj,
    references = c("A" = "B", "B" = "B"),
    update_strategy = dat_ice_JR
)

ana_obj_JR <- analyse(
    impute_obj_JR,
    vars = set_vars()
)

pool(ana_obj_JR)
```


## Custom Imputation Strategies

The following imputation strategies are implemented in `rbmi`:

- Missing at Random (MAR)
- Jump to Reference (JR)
- Copy Reference (CR)
- Copy Increments from Reference (CIR)
- Last Mean Carried Forward (LMCF)

In addition, `rbmi` allows the user to implement their own imputation strategy. 
To do this there are three things which the user needs to do:

1. Define their own imputation strategy function. 
2. Specify which patients use this strategy in the `data_ice` dataset provided to `draws()`.
3. Provide the imputation strategy function to `impute()`.

The imputation strategy function must take 3 arguments (`pars_group`, `pars_ref`, and `index_mar`) and calculates the marginal mean trajectory and covariance matrix of a subject's marginal imputation distribution which will then be applied to subjects to which the strategy applies. 
Here, `pars_group` contains the predicted mean trajectory (`pars_group$mu`, a numeric vector) and covariance matrix (`pars_group$sigma`) for a subject conditional on their assigned treatment group and covariates. `pars_ref` contains the corresponding mean trajectory and covariance matrix conditional on the reference group and the subject's covariates. `index_mar` is a logical vector which specifies for each visit whether the visit is unaffected by an ICE handled using reference-based methods or not. As an example, the user can check how the CIR strategy was implemented by looking at function `strategy_CIR()`.

```{r}
strategy_CIR()
```

To further illustrate this for a simple example, assume that a strategy is to be implemented according to which the marginal mean of the imputation distribution is equal to the marginal mean trajectory for the subject according to their assigned group and covariates up to the ICE and equal to the average of the visit-wise marginal means based on the subjects covariates and the assigned group or the reference group, respectively. For the covariance matrix of the marginal imputation distribution, the covariance matrix from the assigned group is taken. 


To do this, we first need to define the imputation function which for this example could be coded as: 

```{r}
strategy_AVG <- function(pars_group, pars_ref, index_mar) {
    mean_xy <- function(x, y) mean(c(x, y))
    mu_mean <- mapply(
        mean_xy,
        pars_group$mu,
        pars_ref$mu,
        SIMPLIFY = T
    )
    x <- pars_group
    x$mu[!index_mar] <- mu_mean[!index_mar]
    return(x)
}
```

And an example showing its use:
```{r}
pars_group <- list(
    mu = c(1, 2, 3),
    sigma = as_vcov(c(1, 3, 2), c(0.4, 0.5, 0.45))
)

pars_ref <- list(
    mu = c(5, 6, 7),
    sigma = as_vcov(c(2, 1, 1), c(0.7, 0.8, 0.5))
)

index_mar <- c(TRUE, TRUE, FALSE)

strategy_AVG(pars_group, pars_ref, index_mar)
```

To incorporate this into `rbmi`, `data_ice` needs to be updated such that subjects are 
specified as using the `AVG` imputation strategy. Additionally, the function needs
to be provided to `impute()` via the `getStrategies()` function as shown below:

```{r}
dat_ice$strategy <- "AVG"
dat_ice

draw_obj <- draws(
    data = dat,
    data_ice = dat_ice,
    vars = vars,
    method = method_approxbayes(n_sample=10)
)

impute_obj <- impute(
    draw_obj,
    references = c("A" = "B", "B" = "B"),
    strategies = getStrategies(AVG = strategy_AVG)
)
```

## Custom Analysis Functions

By default `rbmi` will analyse the data by using the `ancova()` function as the analysis function which fits 
an ANCOVA model to the outcomes from each visit separately,
and returns the "treatment effect" estimate as well as the corresponding least square means
for each group. If the user wants to perform a different analysis, or return different
statistics from the analysis, then this can be done by using a custom analysis function.
Beware that for conditional mean imputation, the consistency of treatment effect estimation
has only been formally established for analysis functions corresponding to linear models (such as ANCOVA) and caution is 
required when applying alternative analysis functions.

The custom analysis function must take a `data.frame` as its 
first argument and return a named `list` with each element itself being a `list`
containing a at a minimum a point estimate, called `est`. 
For method `method_bayes()` or `method_approxbayes()`, the list must additionally contain a 
standard error (element `se`) and, if available, the degrees of freedom of the complete-data analysis model (element `df`). 

As an example, let's say that the analysis comparing the proportion of subjects with an outcome > 10 at the last 
visit between the groups without any covariate adjustment. This could then lead to the following (naive) analysis function:

```{r}
compare_prop_lastvisit <- function(data,...){
  fit <- summary(glm(I(outcome>10)~group,family=binomial(),data=data[data[[visit]] == "visit_3", ]))
  res <- list(est = fit$coefficients["groupB","Estimate"], se = fit$coefficients["groupB","Std. Error"], df =Inf)
  return(res)
}
```

This analysis function can then be used in combination with `analyse()` as follows:

```{r}
anl_obj <- analyse(
    imputations = impute_obj_CIR,
    fun = compare_prop_lastvisit)

pool(anl_obj)
```

## Delta Adjustment

The `delta` argument of `analyse()` allows users to modify the outcome variable
which can be utilised as part of a tipping point or sensitivity analysis. To do 
this, the user needs to provide a `data.frame` containing a column for the subject
and visit which identifies the observation to be adjusted, and then a 3rd column
called `delta` which specifies the value which will be added to the outcome prior to the analysis. 

The `delta_template()` function creates a skeleton `data.frame` containing
1 row per subject per visit with the value of delta set to 0 for all observations.
The `delta_template()` function has two additional arguments `delta`
and `dlag` which allow the user to specify initial cumulative delta values based upon a
default value and a scaling coefficient based upon how far away the visit
in question is from the ICE visit. 

More specifically; the `delta` argument specifies the default amount of delta
that should be applied to each visit (if it was both post-ICE & unobserved), whilst
`dlag` specifies the scaling coefficient to be applied based upon the visits proximity
to the ICE visit. This is perhaps best illustrated with an example:

Let `delta = c(5,6,7,8)` and `dlag=c(1,2,3,4)` (i.e. assuming there are 4 visits) and lets 
say that the subject had an ICE on visit 2. The calculation would then be as follows:

```
v1  v2  v3  v4
--------------
 5   6   7   8  # delta assigned to each visit
 0   1   2   3  # scaling starting from the first visit after the subjects ICE
--------------
 0   6  14  24  # delta * scaling
--------------
 0   6  20  44  # accumulative sum / delta to be applied to each visit
```

That is to say the subject would have a delta offset of 0 applied for visit-1, 6 for 
visit-2, 20 for visit-3 and 44 for visit-4. As a comparison, lets say that the subject 
instead had their ICE on visit 3, the calculation would then be as follows:

```
v1  v2  v3  v4
--------------
 5   6   7   8  # delta assigned to each visit
 0   0   1   2  # scaling starting from the first visit after the subjects ICE
--------------
 0   0   7  16  # delta * scaling
--------------
 0   0   7  23  # accumulative sum / delta to be applied to each visit
 ```
 
In terms of practical usage, lets say that you wanted a delta of 5 to be used for all
post ICE visits regardless of their proximity to the ICE visit. This can be achieved
by setting `delta = c(5,5,5,5)` and `dlag = c(1,0,0,0)`. For example lets say a subject
had their ICE on visit-1, then the calculation would be as follows:

```
v1  v2  v3  v4
--------------
 5   5   5   5  # delta assigned to each visit
 1   0   0   0  # scaling starting from the first visit after the subjects ICE
--------------
 5   0   0  0  # delta * scaling
--------------
 5   5   5  5  # accumulative sum / delta to be applied to each visit
 ```
 
Another way of using these arguments is to set delta to be the difference in time 
between visits and dlag to be the amount of delta per unit of time. For example 
lets say that we have a visit on weeks 1, 5, 6 & 9 and that we want a delta of 3
to be applied for each week after an ICE. This can be achieved by setting 
`delta = c(0,4,1,3)` (the difference in weeks between each visit) and `dlag = c(3, 3, 3, 3)`. 
For example lets say we have a subject who had their ICE on week-5 (i.e. visit-2) then 
the calculation would be:

```
v1  v2  v3  v4
--------------
 0   4   1   3  # delta assigned to each visit
 0   0   3   3  # scaling starting from the first visit after the subjects ICE
--------------
 0   0   3   9  # delta * scaling
--------------
 0   0   3  12  # accumulative sum / delta to be applied to each visit
```

i.e. on week-6 (1 week after the ICE) they have a delta of 3 and on week-9 (4 weeks
after the ICE) they have a delta of 12


To show this in action, lets say that we want a constant delta of 5 to be applied (regardless of
the lag) to all unobserved post-ICE visits in the treatment arm only. This can be achieved as follows:

First use the `delta` and `dlag` arguments of `delta_template()` to setup a template `data.frame`
in which every unobserved post-ICE visit has a delta of 5:
```{r}
delta_df <- delta_template(
    impute_obj_CIR, 
    delta = c(5, 5, 5), 
    dlag = c(1, 0, 0)
)

as_tibble(delta_df)
```

Next we can use the additional metadata variables provided by `delta_template()` to  manually 
reset the delta values for the control group back to 0:
```{r}
delta_df2 <- delta_df %>% 
    mutate(delta = if_else(group == "B", 0, delta))

as_tibble(delta_df2)
```

Finally we can now use our delta `data.frame` to apply our desired delta offset to our analysis:
```{r}
anl_delta <- analyse(impute_obj_CIR, delta = delta_df2, vars = set_vars())
pool(anl_delta)  
```


Please note that in the case of observed post-ICE data, `delta_template()` will calculate the delta for all
observations assuming that all post-ICE data are missing; it will then set the value of `delta` to
0 for those observations that were actually observed. If you wish to retain the value of `delta`
for the observed post-ICE visits then you can use the `missing_only = FALSE` argument to do so I.e.:

```{r}
delta_template(
    impute_obj_CIR, 
    delta = c(5, 5, 5), 
    dlag = c(1, 0, 0),
    missing_only = FALSE
) %>% 
    as_tibble()
```
